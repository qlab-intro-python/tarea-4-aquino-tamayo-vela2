{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tarea N췈 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fecha y hora de entrega: Domingo 12 de enero, 11:59pm\n",
    "- Agregue los nombres de las personas con las que discuti칩 esta tarea: __Diego Aquino__, __Jose Tamayo__, __Franco Vela__\n",
    "- Env칤e su tarea haciendo el `push` de su c칩digo a su repo en GitHub Classroom: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluaci칩n\n",
    "\n",
    "- Nota: **16/20**\n",
    "\n",
    "춰Buen trabajo en general!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Mercado de autos usados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importa el conjunto de datos `neoauto_20240924.csv`\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      value  item_id  item_price               item_name item_category  \\\n",
      "0     29200  1807331     29200.0       toyota hilux 2021         autos   \n",
      "1     98500  1807393     98500.0       lexus lx 600 2023         autos   \n",
      "2     16800  1739308     17800.0          bmw 520-i 2016         autos   \n",
      "3     15900  1805714     16900.0  chevrolet captiva 2021         autos   \n",
      "4     12500  1806332     12500.0     dfsk glory 500 2023         autos   \n",
      "...     ...      ...         ...                     ...           ...   \n",
      "4036  18000  1805535     18000.0     mini 5 puertas 2018         autos   \n",
      "4037  15000  1805482     16000.0           bmw 120i 2016         autos   \n",
      "4038   9000  1805528     10000.0     volkswagen gol 2022         autos   \n",
      "4039  30500  1805518     31500.0             bmw x5 2016         autos   \n",
      "4040   5500  1805432      5500.0       suzuki swift 2008         autos   \n",
      "\n",
      "     item_category_2  item_brand  item_km  item_year        item_transmission  \\\n",
      "0            Pick Up      TOYOTA  51635.0       2021                 Mec치nica   \n",
      "1     Camionetas Suv       LEXUS  15000.0       2023  Autom치tica - Secuencial   \n",
      "2              Sedan         BMW  66000.0       2016  Autom치tica - Secuencial   \n",
      "3     Camionetas Suv   CHEVROLET  40300.0       2021  Autom치tica - Secuencial   \n",
      "4     Camionetas Suv        DFSK  33000.0       2023                 Mec치nica   \n",
      "...              ...         ...      ...        ...                      ...   \n",
      "4036       Hatchback        MINI  32500.0       2018               Autom치tica   \n",
      "4037       Deportivo         BMW  83000.0       2016  Autom치tica - Secuencial   \n",
      "4038           Sedan  VOLKSWAGEN  43000.0       2022                 Mec치nica   \n",
      "4039  Camionetas Suv         BMW  32000.0       2016  Autom치tica - Secuencial   \n",
      "4040       Hatchback      SUZUKI   1600.0       2008               Autom치tica   \n",
      "\n",
      "      ... item_location_province    item_tag               item_advertiser  \\\n",
      "0     ...                   lima  Como nuevo            Erick Baz치n Ubaldo   \n",
      "1     ...                   lima  Como nuevo        Asesor Gabriel NovoCar   \n",
      "2     ...                   lima     Ocasi칩n                 Carlos Chauca   \n",
      "3     ...                  santa     Premium  Darwin Am칠rico Barr칩n Pastor   \n",
      "4     ...                   lima     Premium             GORDILLO FERNANDO   \n",
      "...   ...                    ...         ...                           ...   \n",
      "4036  ...                   lima         NaN               elizabeth arias   \n",
      "4037  ...                   lima         NaN              Fabrizio Canales   \n",
      "4038  ...                   lima         NaN         Mario Toledo Castillo   \n",
      "4039  ...                   lima         NaN                    SHH Hearne   \n",
      "4040  ...                   lima         NaN                 Susana Pati침o   \n",
      "\n",
      "     item_credit item_verified item_financed_by  santander_price  \\\n",
      "0           True          True        Santander              NaN   \n",
      "1          False          True              NaN              NaN   \n",
      "2           True          True        Santander          16800.0   \n",
      "3           True          True        Santander          15900.0   \n",
      "4           True          True        Santander              NaN   \n",
      "...          ...           ...              ...              ...   \n",
      "4036        True         False        Santander              NaN   \n",
      "4037        True         False        Santander          15000.0   \n",
      "4038        True         False        Santander           9000.0   \n",
      "4039        True         False        Santander          30500.0   \n",
      "4040       False         False              NaN              NaN   \n",
      "\n",
      "                          item_publication_slug item_publication_type  \\\n",
      "0          auto/usado/toyota-hilux-2021-1807331               PREMIUM   \n",
      "1          auto/usado/lexus-lx-600-2023-1807393               PREMIUM   \n",
      "2             auto/usado/bmw-520-i-2016-1739308               PREMIUM   \n",
      "3     auto/usado/chevrolet-captiva-2021-1805714               PREMIUM   \n",
      "4        auto/usado/dfsk-glory-500-2023-1806332               PREMIUM   \n",
      "...                                         ...                   ...   \n",
      "4036     auto/usado/mini-5-puertas-2018-1805535              GRATUITO   \n",
      "4037           auto/usado/bmw-120i-2016-1805482              GRATUITO   \n",
      "4038     auto/usado/volkswagen-gol-2022-1805528              GRATUITO   \n",
      "4039             auto/usado/bmw-x5-2016-1805518              GRATUITO   \n",
      "4040       auto/usado/suzuki-swift-2008-1805432              GRATUITO   \n",
      "\n",
      "      item_publication_type_Id  \n",
      "0                           25  \n",
      "1                           25  \n",
      "2                           25  \n",
      "3                           25  \n",
      "4                           25  \n",
      "...                        ...  \n",
      "4036                        27  \n",
      "4037                        27  \n",
      "4038                        27  \n",
      "4039                        27  \n",
      "4040                        27  \n",
      "\n",
      "[4041 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta del archivo CSV\n",
    "ruta_archivo = \"C:/Users/ediso/OneDrive/Documentos/GitHub/tarea-4-aquino-tamayo-vela2/neoauto_20240924.csv\"\n",
    "\n",
    "# Cargar el archivo CSV en un DataFrame\n",
    "datos = pd.read_csv(ruta_archivo)\n",
    "print(datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 쮺u치l es el precio promedio de los autos de cada marca (`item_brand`) publicados en cada subcategor칤a (`item_category_2`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_brand    item_category_2\n",
      "ALFA-ROMEO    Hatchback            8500.000000\n",
      "              Sedan                2500.000000\n",
      "ASTON MARTIN  Camionetas Suv     229000.000000\n",
      "              Deportivo          169990.000000\n",
      "              Sedan              149900.000000\n",
      "                                     ...      \n",
      "VOLVO         Camionetas Suv      41801.707317\n",
      "              Deportivo            8800.000000\n",
      "              Hatchback           12772.500000\n",
      "              Sedan               11458.333333\n",
      "              Station Wagon        6100.000000\n",
      "Name: item_price, Length: 202, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Se agrupan datos por marca y subcategoria, hallando el promedio para cada uno\n",
    "precio_promedio_por_marca_y_subcategoria = datos.groupby(['item_brand', 'item_category_2'])['item_price'].mean()\n",
    "\n",
    "# Se muestran los resultados de los promedios\n",
    "print(precio_promedio_por_marca_y_subcategoria)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 쮺u치ntos autos tienen m치s de 100,000 kil칩metros (`item_km`) pero un precio (`item_price`) menor al promedio general?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497\n"
     ]
    }
   ],
   "source": [
    "# Soluci칩n\n",
    "promedios = datos['item_price'].mean()\n",
    "\n",
    "cantautos = datos[\n",
    "    (datos['item_km'] > 100000) & (datos['item_price'] < precio_promedio_general)\n",
    "].shape[0]\n",
    "\n",
    "print(cantautos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Encuentra el modelo (`item_name`) m치s caro y el m치s barato de cada marca (`item_brand`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       modelo_mas_caro               modelo_mas_barato\n",
      "item_brand                                                            \n",
      "ALFA-ROMEO         alfa-romeo 147 2006         alfa-romeo alfasud 1982\n",
      "ASTON MARTIN     aston martin dbx 2021          aston martin db11 2017\n",
      "AUDI                    audi rs 6 2024                    audi a4 2015\n",
      "AUSTIN         austin mini cooper 1970         austin mini cooper 1970\n",
      "BAIC                     baic x55 2021                  baic plus 2018\n",
      "...                                ...                             ...\n",
      "SWM                   swm g05 pro 2022                swm g05 pro 2022\n",
      "TOYOTA               toyota hilux 2019  toyota land cruiser prado 2011\n",
      "TRIUMPH              triumph tr-7 1971               triumph tr-7 1971\n",
      "VOLKSWAGEN    volkswagen teramont 2023            volkswagen bora 2015\n",
      "VOLVO                 volvo xc-90 2023            volvo 850 turbo 1995\n",
      "\n",
      "[73 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ediso\\AppData\\Local\\Temp\\ipykernel_25944\\1154500406.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  modelo_extremos_por_marca = datos.groupby('item_brand').apply(obtener_modelos_extremos)\n"
     ]
    }
   ],
   "source": [
    "# Soluci칩n\n",
    "\n",
    "def obtener_modelos_extremos(grupo):\n",
    "    grupo_ordenado = grupo.sort_values(by='item_price', ascending=False)\n",
    "    return pd.Series({\n",
    "        'modelo_mas_caro': grupo_ordenado.iloc[0]['item_name'],\n",
    "        'modelo_mas_barato': grupo_ordenado.iloc[-1]['item_name']\n",
    "    })\n",
    "\n",
    "# Aplicar la funci칩n a cada grupo\n",
    "modelo_extremos_por_marca = datos.groupby('item_brand').apply(obtener_modelos_extremos)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(modelo_extremos_por_marca)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Encuentra las tres marcas con mayor n칰mero de autos financiados por Santander (`item_financed_by`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_brand\n",
      "BMW       296\n",
      "TOYOTA    261\n",
      "NISSAN    228\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "autos_santander = datos[datos['item_financed_by'] == 'Santander']\n",
    "\n",
    "# Contar el n칰mero de autos financiados por marca\n",
    "financiados = autos_santander['item_brand'].value_counts().head(3)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(financiados)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Agrupa las publicaciones por tipo de transmisi칩n (`item_transmission`) y calcula la desviaci칩n est치ndar del precio (`item_price`) para cada tipo.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_transmission\n",
      "Autom치tica                 15332.729048\n",
      "Autom치tica - Secuencial    22678.641589\n",
      "Mec치nica                    8137.122127\n",
      "Name: item_price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Soluci칩n\n",
    "\n",
    "# Agrupar por tipo de transmisi칩n y calcular la desviaci칩n est치ndar del precio\n",
    "desviacion_estandar_por_transmision = datos.groupby('item_transmission')['item_price'].std()\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(desviacion_estandar_por_transmision)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 쮺u치l es el kilometraje promedio de las publicaciones con el tag \"Premium\" y de las publicaciones con el tag \"Como nuevo\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kilometraje promedio para 'Premium': 48400.235897435894\n",
      "Kilometraje promedio para 'Como nuevo': 35963.47619047619\n"
     ]
    }
   ],
   "source": [
    "# Soluci칩n\n",
    "\n",
    "# Calcular el kilometraje promedio para cada tag\n",
    "kilometrajeprom = datos.groupby('item_tag')['item_km'].mean()\n",
    "\n",
    "# Filtrar los resultados para los tags \"Premium\" y \"Como nuevo\"\n",
    "kilometraje_promedio_premium = kilometrajeprom.get('Premium', None)\n",
    "kilometraje_promedio_como_nuevo = kilometrajeprom.get('Como nuevo', None)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f\"Kilometraje promedio para 'Premium': {kilometraje_promedio_premium}\")\n",
    "print(f\"Kilometraje promedio para 'Como nuevo': {kilometraje_promedio_como_nuevo}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 쮺u치les son las marcas de veh칤culas para los que todos sus modelos fabricados en los 칰ltimos 5 a침os tienen al menos 5 publicaciones cada una?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AUDI', 'BMW', 'CHEVROLET', 'DFSK', 'FIAT', 'FORD', 'HAVAL', 'HONDA', 'HYUNDAI', 'JEEP', 'KIA', 'MAZDA', 'MG', 'NISSAN', 'PEUGEOT', 'RENAULT', 'SUBARU', 'TOYOTA', 'VOLKSWAGEN', 'VOLVO']\n"
     ]
    }
   ],
   "source": [
    "# Soluci칩n\n",
    "import datetime\n",
    "\n",
    "# Calcular el a침o actual\n",
    "a침o = datetime.datetime.now().year\n",
    "\n",
    "# Filtrar autos fabricados en los 칰ltimos 5 a침os\n",
    "ultimosa침os = datos[datos['item_year'] >= (a침o - 5)]\n",
    "\n",
    "# Contar publicaciones por marca y modelo\n",
    "numpubli =ultimosa침os.groupby(['item_brand', 'item_name']).size()\n",
    "\n",
    "# Filtrar modelos con al menos 5 publicaciones\n",
    "cincopubl = numpubli[numpubli >= 5]\n",
    "\n",
    "# Contar cu치ntos modelos cumplen por marca\n",
    "cumplen = cincopubl.groupby(level=0).size()\n",
    "\n",
    "# Filtrar marcas donde todos sus modelos cumplen con la condici칩n\n",
    "marcas_cumplen = cumplen[cumplen ==\n",
    "                                               cincopubl.groupby(level=0).count()].index\n",
    "\n",
    "# Mostrar las marcas que cumplen la condici칩n\n",
    "print(marcas_cumplen.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evoluci칩n econ칩mica internacional**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importa el conjunto de datos de la hoja \"Data\" del archivo `pwt1001.xlsx`. El diccionario de variables est치 disponible en la hoja \"Legend\" del archivo Excel.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calcule el PBI per c치pita real ajustado por poder de paridad de compra (PPP). Use la variable de PBI que se calcula por gasto y la poblaci칩n. 쮺u치les son los 10 pa칤ses top?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  country   rgdpe_pc_ppp\n",
      "102            Luxembourg  112941.453342\n",
      "104      China, Macao SAR  105337.890061\n",
      "139                 Qatar  103445.127269\n",
      "79                Ireland  102353.631443\n",
      "146             Singapore   88619.305271\n",
      "22                Bermuda   79967.588736\n",
      "31            Switzerland   71831.637057\n",
      "43         Cayman Islands   70208.345162\n",
      "4    United Arab Emirates   69753.215256\n",
      "26      Brunei Darussalam   67555.392597\n"
     ]
    }
   ],
   "source": [
    "# Soluci칩n\n",
    "import pandas as pd\n",
    "data = pd.read_excel(\"C:/Users/HP/Documents/GitHub/tarea-4-aquino-tamayo-vela2/pwt1001.xlsx\", sheet_name='Data')\n",
    "\n",
    "data['rgdpe_pc_ppp'] = data['rgdpe'] / data['pop']\n",
    "\n",
    "recent_years = data.groupby('countrycode')['year'].max().reset_index()\n",
    "recent_data = pd.merge(recent_years, data, on=['countrycode', 'year'])\n",
    "\n",
    "top_10_countries = recent_data.nlargest(10, 'rgdpe_pc_ppp')[['country', 'rgdpe_pc_ppp']]\n",
    "\n",
    "print(top_10_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Genera el r치nking de los pa칤ses con el mayor incremento del PBI per c치pita real PPP entre los a침os 1990 y 2019. 쮻칩nde se ubica Per칰? Para los pa칤ses que no tengan informaci칩n para dichos a침os, puede utilizar datos provenientes de hasta dos a침os antes o despu칠s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 pa칤ses con mayor incremento en PBI per c치pita real PPP:\n",
      "            country    ppp_growth\n",
      "0           Ireland  82726.713568\n",
      "1  China, Macao SAR  78788.824158\n",
      "2             Qatar  75444.868541\n",
      "3         Singapore  67092.155508\n",
      "4        Luxembourg  66997.038564\n",
      "5           Bermuda  48231.808944\n",
      "6             Malta  35968.133995\n",
      "7            Norway  34098.305410\n",
      "8            Kuwait  34055.592958\n",
      "9      Saudi Arabia  32993.864961\n",
      "\n",
      "Per칰 se encuentra en la posici칩n: 82\n"
     ]
    }
   ],
   "source": [
    "# Soluci칩n\n",
    "data_filtered = data[(data['year'] >= 1988) & (data['year'] <= 2021)]\n",
    "\n",
    "data_1990 = data_filtered.loc[data_filtered['year'].sub(1990).abs().groupby(data_filtered['countrycode']).idxmin()]\n",
    "data_2019 = data_filtered.loc[data_filtered['year'].sub(2019).abs().groupby(data_filtered['countrycode']).idxmin()]\n",
    "\n",
    "merged_data = pd.merge(\n",
    "    data_1990[['countrycode', 'country', 'rgdpe_pc_ppp']].rename(columns={'rgdpe_pc_ppp': 'rgdpe_pc_ppp_1990'}),\n",
    "    data_2019[['countrycode', 'rgdpe_pc_ppp']].rename(columns={'rgdpe_pc_ppp': 'rgdpe_pc_ppp_2019'}),\n",
    "    on='countrycode'\n",
    ")\n",
    "\n",
    "merged_data['ppp_growth'] = merged_data['rgdpe_pc_ppp_2019'] - merged_data['rgdpe_pc_ppp_1990']\n",
    "\n",
    "ranking = merged_data.sort_values(by='ppp_growth', ascending=False).reset_index(drop=True)\n",
    "\n",
    "peru_position = ranking[ranking['countrycode'] == 'PER'].index[0] + 1 if 'PER' in ranking['countrycode'].values else None\n",
    "\n",
    "top_10_countries = ranking[['country', 'ppp_growth']].head(10)\n",
    "print(\"Top 10 pa칤ses con mayor incremento en PBI per c치pita real PPP:\")\n",
    "print(top_10_countries)\n",
    "\n",
    "if peru_position:\n",
    "    print(f\"\\nPer칰 se encuentra en la posici칩n: {peru_position}\")\n",
    "else:\n",
    "    print(\"\\nPer칰 no tiene datos disponibles para este an치lisis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Para el periodo 2010-2019, calcule el promedio del 칤ndice del capital humano. 쯈u칠 relaci칩n existe entre esta variable y el PBI per c치pita real PPP calculado previamente? 쯫 el n칰mero de horas laboradas al a침o por los trabajadores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen de datos combinados:\n",
      "           hc_avg        ppp_avg      avh_avg\n",
      "count  145.000000     183.000000    66.000000\n",
      "mean     2.608130   21824.936268  1874.186633\n",
      "std      0.688566   22370.442294   270.522674\n",
      "min      1.195960     760.055772  1390.170680\n",
      "25%      2.034321    5221.510286  1669.381684\n",
      "50%      2.674898   14008.432573  1849.780904\n",
      "75%      3.164617   30751.445052  2082.694520\n",
      "max      3.738265  127462.470192  2444.905644\n"
     ]
    }
   ],
   "source": [
    "# Soluci칩n\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data['rgdpe_pc_ppp'] = data['rgdpe'] / data['pop']\n",
    "\n",
    "data_period = data[(data['year'] >= 2010) & (data['year'] <= 2019)]\n",
    "\n",
    "hc_avg = data_period.groupby('countrycode')['hc'].mean().reset_index()\n",
    "hc_avg = hc_avg.rename(columns={'hc': 'hc_avg'})\n",
    "\n",
    "ppp_avg = data_period.groupby('countrycode')['rgdpe_pc_ppp'].mean().reset_index().rename(columns={'rgdpe_pc_ppp': 'ppp_avg'})\n",
    "avh_avg = data_period.groupby('countrycode')['avh'].mean().reset_index().rename(columns={'avh': 'avh_avg'})\n",
    "\n",
    "combined_data = hc_avg.merge(ppp_avg, on='countrycode').merge(avh_avg, on='countrycode')\n",
    "\n",
    "print(\"Resumen de datos combinados:\")\n",
    "print(combined_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. A partir de la variable del precio de los hogares, calcula los pa칤ses y los a침os en los cuales se registr칩 la mayor inflaci칩n anual para todo el periodo de tiempo disponible en la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mayor inflaci칩n anual registrada:\n",
      "Pa칤s: Venezuela (Bolivarian Republic of)\n",
      "A침o: 2017\n",
      "Inflaci칩n: 355.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_17568\\2485677633.py:7: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  data_sorted['inflation'] = data_sorted.groupby('country')['pl_c'].pct_change() * 100\n"
     ]
    }
   ],
   "source": [
    "# Soluci칩n\n",
    "if {'country', 'year', 'pl_c'}.issubset(data.columns):\n",
    "    data_sorted = data.sort_values(by=['country', 'year'])\n",
    "    \n",
    "    data_sorted['inflation'] = data_sorted.groupby('country')['pl_c'].pct_change() * 100\n",
    "    \n",
    "    max_inflation_row = data_sorted.loc[data_sorted['inflation'].idxmax()]\n",
    "    \n",
    "    print(f\"Mayor inflaci칩n anual registrada:\")\n",
    "    print(f\"Pa칤s: {max_inflation_row['country']}\")\n",
    "    print(f\"A침o: {int(max_inflation_row['year'])}\")\n",
    "    print(f\"Inflaci칩n: {max_inflation_row['inflation']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 쮺u치les son los pa칤ses con la mayor cantidad de missing values en la variable de productividad total de factores a precios corrientes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n",
      "Albania                           70\n",
      "Turkmenistan                      70\n",
      "Sint Maarten (Dutch part)         70\n",
      "Grenada                           70\n",
      "Ghana                             70\n",
      "Georgia                           70\n",
      "Gambia                            70\n",
      "St. Vincent and the Grenadines    70\n",
      "Pakistan                          70\n",
      "Ethiopia                          70\n",
      "Name: ctfp, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Soluci칩n\n",
    "\n",
    "if 'ctfp' in data.columns and 'country' in data.columns:\n",
    "   \n",
    "    missing_values = data.groupby('country')['ctfp'].apply(lambda x: x.isnull().sum())\n",
    "    \n",
    "    missing_values_sorted = missing_values.sort_values(ascending=False)\n",
    "    \n",
    "    print(missing_values_sorted.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.  Agrupa los datos por pa칤s y calcula el promedio de las horas trabajadas anuales (avh) y de la educaci칩n promedio (hc) para el periodo 2000-2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedios de horas trabajadas anuales y educaci칩n promedio (2000-2020):\n",
      "                                            avh        hc\n",
      "country                                                  \n",
      "Albania                                     NaN  2.895579\n",
      "Algeria                                     NaN  2.080837\n",
      "Angola                                      NaN  1.399746\n",
      "Anguilla                                    NaN       NaN\n",
      "Antigua and Barbuda                         NaN       NaN\n",
      "...                                         ...       ...\n",
      "Venezuela (Bolivarian Republic of)  1874.516018  2.538335\n",
      "Viet Nam                            2243.230824  2.407059\n",
      "Yemen                                       NaN  1.444725\n",
      "Zambia                                      NaN  2.304970\n",
      "Zimbabwe                                    NaN  2.388763\n",
      "\n",
      "[183 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Soluci칩n\n",
    "filtered_data = data[(data['year'] >= 2000) & (data['year'] <= 2020)]\n",
    "if {'country', 'avh', 'hc'}.issubset(filtered_data.columns):\n",
    "\n",
    "    averages = filtered_data.groupby('country')[['avh', 'hc']].mean()\n",
    "\n",
    "    print(\"Promedios de horas trabajadas anuales y educaci칩n promedio (2000-2020):\")\n",
    "    print(averages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.  Genere una variable que ordene a los pa칤ses seg칰n el porcetaje de formaci칩n brutal de capital del 2019. Luego, estable diez grupos a manera de deciles. 쮼n qu칠 decil se ubica P칠ru? Vuelva a calcular usando la informaci칩n de 1990. 쮼l Per칰 se mantiene en el mismo d칠cil o cambia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per칰 en 2019 est치 en el decil: 5\n",
      "Per칰 en 1990 est치 en el decil: 4.0\n",
      "Per칰 cambia de decil entre 1990 y 2019.\n"
     ]
    }
   ],
   "source": [
    "# Soluci칩n\n",
    "data_2019 = data[data['year'] == 2019]\n",
    "data_1990 = data[data['year'] == 1990]\n",
    "\n",
    "if {'country', 'csh_i'}.issubset(data.columns):\n",
    "    data_2019 = data_2019.sort_values(by='csh_i', ascending=False)\n",
    "    data_2019['decile_2019'] = pd.qcut(data_2019['csh_i'], 10, labels=False) + 1  \n",
    "\n",
    "    data_1990 = data_1990.sort_values(by='csh_i', ascending=False)\n",
    "    data_1990['decile_1990'] = pd.qcut(data_1990['csh_i'], 10, labels=False) + 1  \n",
    "    \n",
    "    peru_2019 = data_2019[data_2019['country'] == 'Peru']['decile_2019'].values\n",
    "    peru_1990 = data_1990[data_1990['country'] == 'Peru']['decile_1990'].values\n",
    "\n",
    "   \n",
    "    print(f\"Per칰 en 2019 est치 en el decil: {peru_2019[0] if len(peru_2019) > 0 else 'No disponible'}\")\n",
    "    print(f\"Per칰 en 1990 est치 en el decil: {peru_1990[0] if len(peru_1990) > 0 else 'No disponible'}\")\n",
    "\n",
    "    if peru_2019 and peru_1990:\n",
    "        if peru_2019[0] == peru_1990[0]:\n",
    "            print(\"Per칰 se mantiene en el mismo decil en 1990 y 2019.\")\n",
    "        else:\n",
    "            print(\"Per칰 cambia de decil entre 1990 y 2019.\")\n",
    "    else:\n",
    "        print(\"No hay informaci칩n suficiente para Per칰 en uno o ambos a침os.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Transacciones Financieras**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importa el conjunto de datos `base_financiera.csv`\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Filtra todas las transacciones de tipo \"Debit\" en las que el monto sea mayor a 200, y calcula el monto total de esas transacciones. Adem치s, determina cu치ntos clientes 칰nicos realizaron esas transacciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Transaction_ID Customer_ID        Date   Amount Transaction_Type Region\n",
      "1               1002        C016  2023-01-02   906.97            Debit  South\n",
      "2               1003        C033  2023-01-03  1579.96            Debit  South\n",
      "4               1005        C035  2023-01-05  3719.21            Debit  North\n",
      "5               1006        C078  2023-01-06  3127.58            Debit   West\n",
      "8               1009        C031  2023-01-09  4044.73            Debit   West\n",
      "...              ...         ...         ...      ...              ...    ...\n",
      "2016            1747        C171  2023-01-27  2498.66            Debit   West\n",
      "2021            2665        C072  2023-01-25  3060.79            Debit  South\n",
      "2026            2180        C072  2023-01-20  4406.49            Debit  South\n",
      "2027            1965        C022  2023-01-05   676.48            Debit  North\n",
      "2028            1793        C107  2023-02-02  4099.63            Debit  North\n",
      "\n",
      "[1094 rows x 6 columns]\n",
      "游늷 La suma total de las transaciones mayores a 200 u.m. realizadas con tarjeta de d칠bito es de 2847871.75 u.m.\n",
      "游늷 El n칰mero total de clientes 칰nicos que realizaron transacciones mayores a 200 u.m con tarjeta de d칠bito fue de 200\n"
     ]
    }
   ],
   "source": [
    "# Soluci칩n \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Cargamos los datos desde el archivo CSV\n",
    "data_frame_BF = pd.read_csv(\"base_financiera.csv\")\n",
    "\n",
    "# Filtramos las transacciones de tipo \"Debit\" con monto mayor a 200\n",
    "filtro_debit_mayor_a_200 = (data_frame_BF[\"Transaction_Type\"] == \"Debit\") & (data_frame_BF[\"Amount\"] > 200) # Mediante un conector l칩gico establecemos las condiciones de inter칠s\n",
    "transacciones_filtradas = data_frame_BF[filtro_debit_mayor_a_200] # Hacemos uso del filtro en el data frame\n",
    "print(transacciones_filtradas)\n",
    "\n",
    "# Calculamos el monto total de las transacciones mayores a 200 u.m. realizadas con tarjeta de d칠bito\n",
    "monto_total = transacciones_filtradas[\"Amount\"].sum() # Sumamos los valores ya filtrados de la columna \"Amount\"\n",
    "print(f\"游늷 La suma total de las transaciones mayores a 200 u.m. realizadas con tarjeta de d칠bito es de {monto_total} u.m.\")\n",
    "\n",
    "# Calculamos el n칰mero de clientes 칰nicos que reaizaron estas transacciones\n",
    "clientes_unicos = len(transacciones_filtradas[\"Customer_ID\"].unique()) # Hacemos uso de la funci칩n unique para filtrar a los clientes 칰nicos. Usamos len() para la cantidad total \n",
    "print(f\"游늷 El n칰mero total de clientes 칰nicos que realizaron transacciones mayores a 200 u.m con tarjeta de d칠bito fue de {clientes_unicos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Identifica las transacciones con valores nulos en la columna (`Amount`) . Rellena esos valores con la mediana de los montos por tipo de transacci칩n (`Transaction_Type`) y luego calcula el monto total de transacciones por regi칩n (`region`) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahora, luego de rellenar los valores con la mediana de los montos por tipo de transacci칩n, existe un total de 0 valores nulos en la columna Amount\n",
      "Considerando los cambios aplicados, calculamos el monto total de transacciones realizadas por Region\n",
      "East     1268860.23\n",
      "North    1320785.52\n",
      "South    1207824.17\n",
      "West     1233882.08\n",
      "Name: Amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Soluci칩n\n",
    "\n",
    "# Identificamos las transacciones con valores nulos de la columna \"Amount\"\n",
    "filtro_null_values_amount = data_frame_BF[\"Amount\"].isnull() # Filtramos los valores nulos de la columna \"Amount\". Existen 113\n",
    "null_values_amount = data_frame_BF[filtro_null_values_amount] # Aplicamos el filtro al data frame\n",
    "\n",
    "# Rellenamos valores nulos de la columna \"Amount\" con la mediana de los montos por tipo de transacci칩n\n",
    "filtro_debit = data_frame_BF[data_frame_BF[\"Transaction_Type\"] == \"Debit\"] # Filtramos las transacciones con d칠bito\n",
    "filtro_credit = data_frame_BF[data_frame_BF[\"Transaction_Type\"] == \"Credit\"] # Filtramos las transacciones con cr칠dito\n",
    "\n",
    "median_debit_amounts = filtro_credit[\"Amount\"].median() # Calculamos la mediana de los montos realizados con d칠bito (2424.42)\n",
    "median_credit_amounts = filtro_debit[\"Amount\"].median() # Calculamos la mediana de los montos realizados con cr칠dito (2461.04)\n",
    "\n",
    "data_frame_BF.loc[ (data_frame_BF[\"Transaction_Type\"] == \"Debit\") & (data_frame_BF[\"Amount\"].isnull()), \"Amount\"] = median_debit_amounts # Rellenamos los valores nulos de categor칤a d칠bito \n",
    "data_frame_BF.loc[ (data_frame_BF[\"Transaction_Type\"] == \"Credit\") & (data_frame_BF[\"Amount\"].isnull()), \"Amount\"] = median_credit_amounts # Rellenamos los valores nulos de categor칤a cr칠dito\n",
    "print(f\"Ahora, luego de rellenar los valores con la mediana de los montos por tipo de transacci칩n, existe un total de {len(null_values_amount)} valores nulos en la columna Amount\")\n",
    "\n",
    "# Ahora vamos a calcular el monto total de transacciones por regi칩n\n",
    "value_of_amount_per_region = data_frame_BF.groupby(\"Region\")[\"Amount\"].sum()\n",
    "print(f\"Considerando los cambios aplicados, calculamos el monto total de transacciones realizadas por {value_of_amount_per_region}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Busca transacciones duplicadas considerando las columnas (`Customer_ID`) y (`Date`). Elimina los duplicados manteniendo solo la primera ocurrencia. Luego, agrupa las transacciones restantes por (`Customer_ID`) y calcula el monto promedio y la cantidad de transacciones por cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Customer_ID  promedio_monto  cantidad_transacciones\n",
      "0          C001     3281.165294                      17\n",
      "1          C002     1881.827778                       9\n",
      "2          C003     3102.125000                      14\n",
      "3          C004     2879.267143                       7\n",
      "4          C005     3364.053333                       6\n",
      "..          ...             ...                     ...\n",
      "195        C196     2566.555000                      10\n",
      "196        C197     2530.674286                      14\n",
      "197        C198     2484.925000                      12\n",
      "198        C199     2934.714000                       5\n",
      "199        C200     2189.666000                       5\n",
      "\n",
      "[200 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Soluci칩n\n",
    "\n",
    "# Eliminamos las transacciones duplicadas de las columnas Customer y Date, manteniendo la primera ocurrencia\n",
    "df_sin_duplicados = data_frame_BF.drop_duplicates(subset=[\"Customer_ID\", \"Date\"], keep = \"first\")\n",
    "\n",
    "# Agrupamos las transacciones restantes y calculamos el monto promedio y cantidad de transacciones por cliente\n",
    "resultados = df_sin_duplicados.groupby(\"Customer_ID\").agg( # Agrupamos cada fila por cliente para juntar todas sus transacciones realizadas\n",
    "    promedio_monto = (\"Amount\", \"mean\"),  # Promedio del monto\n",
    "    cantidad_transacciones = (\"Amount\", \"count\")  # Cantidad de transacciones\n",
    ").reset_index()\n",
    "\n",
    "print(resultados)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
